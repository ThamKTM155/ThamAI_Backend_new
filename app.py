# app.py
import os
import io
from tempfile import NamedTemporaryFile
from flask import Flask, request, jsonify, Response
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI

# Load env
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("‚ö†Ô∏è Warning: OPENAI_API_KEY not set in .env")

# Flask + CORS
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)

# --- Test route
@app.route("/test", methods=["GET"])
def test():
    return jsonify({"message": "‚úÖ K·∫øt n·ªëi backend ThamAI th√†nh c√¥ng!", "status": "ok"}), 200


# --- Chat route
@app.route("/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json(force=True)
        message = (data.get("message") or "").strip()
        if not message:
            return jsonify({"error": "Thi·∫øu n·ªôi dung tin nh·∫Øn"}), 400

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "B·∫°n l√† ThamAI - tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† h·ªØu √≠ch."},
                {"role": "user", "content": message},
            ],
        )
        reply = completion.choices[0].message.content
        return jsonify({"reply": reply}), 200

    except Exception as e:
        print("‚ùå L·ªói /chat:", e)
        return jsonify({"error": "L·ªói n·ªôi b·ªô server", "detail": str(e)}), 500


# --- Whisper (Speech -> Text)
@app.route("/whisper", methods=["POST"])
def whisper():
    try:
        # Expect form-data with field name "file"
        if "file" not in request.files:
            return jsonify({"error": "Kh√¥ng c√≥ file ghi √¢m (field 'file' missing)"}), 400

        audio_file = request.files["file"]
        if audio_file.filename == "":
            return jsonify({"error": "File r·ªóng"}), 400

        # Read bytes and wrap in BytesIO (OpenAI client expects bytes / io.IOBase)
        audio_bytes = audio_file.read()
        if not audio_bytes:
            return jsonify({"error": "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file ghi √¢m"}), 400

        audio_io = io.BytesIO(audio_bytes)

        # Debug info
        print(f"üì• Received audio file: {audio_file.filename}, content_type={audio_file.content_type}, size={len(audio_bytes)} bytes")

        # Call OpenAI transcription
        try:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_io
            )
        except Exception as e:
            print("‚ùå OpenAI transcription error:", e)
            return jsonify({"error": "Whisper l·ªói khi x·ª≠ l√Ω", "detail": str(e)}), 500

        text = getattr(transcript, "text", None) or transcript.get("text") if isinstance(transcript, dict) else None
        if text is None:
            # fallback: try converting to string
            return jsonify({"error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c vƒÉn b·∫£n t·ª´ Whisper", "detail": str(transcript)}), 500

        return jsonify({"text": text}), 200

    except Exception as e:
        print("‚ùå L·ªói /whisper:", e)
        return jsonify({"error": "L·ªói server khi nh·∫≠n file", "detail": str(e)}), 500


# --- Speak (Text -> Speech)
@app.route("/speak", methods=["POST"])
def speak():
    try:
        data = request.get_json(force=True)
        text = (data.get("text") or "").strip()
        voice = (data.get("voice") or "alloy")  # default "alloy" (male-ish) ; frontend may pass "nova" for female

        if not text:
            return jsonify({"error": "Kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ ƒë·ªçc"}), 400

        try:
            # Create speech (this may raise exceptions from OpenAI)
            speech_obj = client.audio.speech.create(
                model="gpt-4o-mini-tts",
                voice=voice,
                input=text
            )
        except Exception as e:
            print("‚ùå OpenAI TTS error:", e)
            # Try to get message from exception object
            return jsonify({"error": "TTS l·ªói khi g·ªçi API", "detail": str(e)}), 500

        # speech_obj should provide bytes via .read() or be bytes-like
        audio_bytes = None
        try:
            if hasattr(speech_obj, "read"):
                audio_bytes = speech_obj.read()
            elif isinstance(speech_obj, (bytes, bytearray)):
                audio_bytes = bytes(speech_obj)
            elif isinstance(speech_obj, dict) and "audio" in speech_obj:
                audio_bytes = speech_obj["audio"]
            else:
                # fallback: try str()
                audio_bytes = str(speech_obj).encode("utf-8")
        except Exception as e:
            print("‚ùå L·ªói ƒë·ªçc d·ªØ li·ªáu √¢m thanh:", e)
            return jsonify({"error": "Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu audio t·ª´ OpenAI", "detail": str(e)}), 500

        # Return audio with proper mimetype
        return Response(audio_bytes, mimetype="audio/mpeg")

    except Exception as e:
        print("‚ùå L·ªói /speak:", e)
        return jsonify({"error": "L·ªói server", "detail": str(e)}), 500


if __name__ == "__main__":
    # Use port 5000 locally
    app.run(host="0.0.0.0", port=5000, debug=True)
